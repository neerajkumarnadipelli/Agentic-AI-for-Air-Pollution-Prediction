{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8ca4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.10.1\n",
      "PennyLane: 0.32.0\n",
      "Loaded shapes:\n",
      " X_train: (994, 5, 10, 10, 24)\n",
      " y_train: (994, 10, 10, 7)\n",
      " X_val  : (213, 5, 10, 10, 24)\n",
      " y_val  : (213, 10, 10, 7)\n",
      " X_test : (214, 5, 10, 10, 24)\n",
      " y_test : (214, 10, 10, 7)\n",
      "PM2.5 target shapes: (994, 10, 10, 1) (213, 10, 10, 1) (214, 10, 10, 1)\n",
      "üöÄ STARTING EXPERT 1: Quantum-Enhanced PM2.5 Predictor\n",
      "\n",
      "============================================================\n",
      "TRAINING EXPERT 1: Quantum-Enhanced PM2.5 Predictor\n",
      "============================================================\n",
      "Creating Expert 1 model...\n",
      "\n",
      "Model Architecture:\n",
      "Model: \"Expert1_QuantumEnhanced_PM25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization (BatchN  (None, 5, 10, 10, 24)    96        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv3d (Conv3D)             (None, 5, 10, 10, 16)     10384     \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 5, 10, 10, 32)     4128      \n",
      "                                                                 \n",
      " global_average_pooling3d (G  (None, 32)               0         \n",
      " lobalAveragePooling3D)                                          \n",
      "                                                                 \n",
      " quantum_enhanced_layer (Qua  (None, 64)               4160      \n",
      " ntumEnhancedLayer)                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " quantum_enhanced_layer_1 (Q  (None, 32)               4128      \n",
      " uantumEnhancedLayer)                                            \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1600)              52800     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 10, 10, 16)        0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 10, 10, 32)        4640      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 10, 10, 16)        4624      \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 10, 10, 8)         1160      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 10, 10, 1)         73        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,321\n",
      "Trainable params: 86,209\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n",
      "\n",
      "Training details:\n",
      "  Samples: 994 training, 213 validation\n",
      "  Input shape: (5, 10, 10, 24)\n",
      "  Target shape: (10, 10, 1)\n",
      "  Model type: Quantum-Enhanced Sequential\n",
      "  Epochs: 100, Batch size: 4\n",
      "\n",
      "Starting training...\n",
      "Epoch 1/100\n",
      "248/249 [============================>.] - ETA: 0s - loss: 0.0422 - mae: 0.1541\n",
      "Epoch 1: val_loss improved from inf to 0.04546, saving model to C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert1_output\\expert1_best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert1_output\\expert1_best_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert1_output\\expert1_best_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/249 [==============================] - 22s 67ms/step - loss: 0.0421 - mae: 0.1539 - val_loss: 0.0455 - val_mae: 0.1507 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "247/249 [============================>.] - ETA: 0s - loss: 0.0268 - mae: 0.1196\n",
      "Epoch 2: val_loss improved from 0.04546 to 0.01135, saving model to C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert1_output\\expert1_best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert1_output\\expert1_best_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert1_output\\expert1_best_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/249 [==============================] - 15s 59ms/step - loss: 0.0270 - mae: 0.1201 - val_loss: 0.0113 - val_mae: 0.0786 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "247/249 [============================>.] - ETA: 0s - loss: 0.0225 - mae: 0.1106\n",
      "Epoch 3: val_loss improved from 0.01135 to 0.01117, saving model to C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert1_output\\expert1_best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert1_output\\expert1_best_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert1_output\\expert1_best_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/249 [==============================] - 17s 66ms/step - loss: 0.0224 - mae: 0.1105 - val_loss: 0.0112 - val_mae: 0.0752 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "248/249 [============================>.] - ETA: 0s - loss: 0.0172 - mae: 0.0964\n",
      "Epoch 4: val_loss improved from 0.01117 to 0.01059, saving model to C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert1_output\\expert1_best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert1_output\\expert1_best_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert1_output\\expert1_best_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/249 [==============================] - 16s 66ms/step - loss: 0.0171 - mae: 0.0963 - val_loss: 0.0106 - val_mae: 0.0738 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "127/249 [==============>...............] - ETA: 3s - loss: 0.0202 - mae: 0.1032"
     ]
    }
   ],
   "source": [
    "# Expert 1: Quantum PM2.5 Predictor - FIXED VARIABLE SCOPE\n",
    "# Using TensorFlow SavedModel format for subclassed models\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''  # comment out to enable GPU\n",
    "\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, optimizers, callbacks\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----------------------------\n",
    "# CONFIG\n",
    "# ----------------------------\n",
    "DATA_DIR = r\"C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\datasets\"\n",
    "OUTPUT_DIR = r\"C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert1_output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "SEQ_LEN = 5\n",
    "PATCH_SIZE = 10\n",
    "CHANNELS = 24\n",
    "PRED_BAND_IDX = 0\n",
    "NUM_QUBITS = 4\n",
    "Q_DEPTH = 2\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 4\n",
    "LR = 1e-3\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"PennyLane:\", qml.__version__)\n",
    "\n",
    "# ----------------------------\n",
    "# Load datasets\n",
    "# ----------------------------\n",
    "\n",
    "def load_npy(name):\n",
    "    path = os.path.join(DATA_DIR, name)\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(path)\n",
    "    return np.load(path)\n",
    "\n",
    "X_train = load_npy(\"X_train.npy\")\n",
    "y_train = load_npy(\"y_train.npy\")\n",
    "X_val = load_npy(\"X_val.npy\")\n",
    "y_val = load_npy(\"y_val.npy\")\n",
    "X_test = load_npy(\"X_test.npy\")\n",
    "y_test = load_npy(\"y_test.npy\")\n",
    "\n",
    "print(\"Loaded shapes:\")\n",
    "print(\" X_train:\", X_train.shape)\n",
    "print(\" y_train:\", y_train.shape)\n",
    "print(\" X_val  :\", X_val.shape)\n",
    "print(\" y_val  :\", y_val.shape)\n",
    "print(\" X_test :\", X_test.shape)\n",
    "print(\" y_test :\", y_test.shape)\n",
    "\n",
    "# Prepare PM2.5 targets\n",
    "def extract_pm25(y):\n",
    "    pm25 = y[..., PRED_BAND_IDX]\n",
    "    return pm25[..., None].astype(np.float32)\n",
    "\n",
    "y_train_pm25 = extract_pm25(y_train)\n",
    "y_val_pm25 = extract_pm25(y_val)\n",
    "y_test_pm25 = extract_pm25(y_test)\n",
    "\n",
    "print(\"PM2.5 target shapes:\", y_train_pm25.shape, y_val_pm25.shape, y_test_pm25.shape)\n",
    "\n",
    "# ----------------------------\n",
    "# Quantum-Enhanced Layer (Saves properly)\n",
    "# ----------------------------\n",
    "\n",
    "class QuantumEnhancedLayer(layers.Layer):\n",
    "    \"\"\"Custom layer that incorporates quantum-inspired operations\"\"\"\n",
    "    \n",
    "    def __init__(self, units, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        # Quantum-inspired weights (complex numbers represented as 2D)\n",
    "        self.quantum_weights = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units, 2),  # Real and imaginary parts\n",
    "            initializer='random_normal',\n",
    "            trainable=True,\n",
    "            name='quantum_weights'\n",
    "        )\n",
    "        self.bias = self.add_weight(\n",
    "            shape=(self.units,),\n",
    "            initializer='zeros',\n",
    "            trainable=True,\n",
    "            name='bias'\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # Quantum-inspired transformation\n",
    "        real_part = tf.matmul(inputs, self.quantum_weights[:, :, 0])\n",
    "        imag_part = tf.matmul(inputs, self.quantum_weights[:, :, 1])\n",
    "        \n",
    "        # Magnitude (quantum probability amplitude inspired)\n",
    "        output = tf.sqrt(real_part**2 + imag_part**2) + self.bias\n",
    "        return tf.nn.relu(output)  # Non-linearity\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"units\": self.units})\n",
    "        return config\n",
    "\n",
    "def create_expert1_quantum_enhanced():\n",
    "    \"\"\"Expert 1 with quantum-enhanced layers (saves properly)\"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.InputLayer(input_shape=(SEQ_LEN, PATCH_SIZE, PATCH_SIZE, CHANNELS)),\n",
    "        \n",
    "        # Spatio-temporal processing\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv3D(16, (3, 3, 3), activation='relu', padding='same'),\n",
    "        layers.Conv3D(32, (2, 2, 2), activation='relu', padding='same'),\n",
    "        layers.GlobalAveragePooling3D(),\n",
    "        \n",
    "        # Quantum-enhanced processing\n",
    "        QuantumEnhancedLayer(64),\n",
    "        layers.Dropout(0.2),\n",
    "        QuantumEnhancedLayer(32),\n",
    "        layers.BatchNormalization(),\n",
    "        \n",
    "        # Spatial reconstruction\n",
    "        layers.Dense(PATCH_SIZE * PATCH_SIZE * 16, activation='relu'),\n",
    "        layers.Reshape((PATCH_SIZE, PATCH_SIZE, 16)),\n",
    "        \n",
    "        # Final refinement\n",
    "        layers.Conv2D(32, 3, activation='relu', padding='same'),\n",
    "        layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
    "        layers.Conv2D(8, 3, activation='relu', padding='same'),\n",
    "        layers.Conv2D(1, 3, activation='linear', padding='same')\n",
    "    ], name=\"Expert1_QuantumEnhanced_PM25\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ----------------------------\n",
    "# Training Setup\n",
    "# ----------------------------\n",
    "\n",
    "def create_expert1_model():\n",
    "    \"\"\"Create Expert 1 model\"\"\"\n",
    "    model = create_expert1_quantum_enhanced()\n",
    "    \n",
    "    optimizer = optimizers.Adam(learning_rate=LR)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_expert1_callbacks():\n",
    "    \"\"\"Create callbacks for training\"\"\"\n",
    "    \n",
    "    # Use TensorFlow SavedModel format\n",
    "    checkpoint_cb = callbacks.ModelCheckpoint(\n",
    "        os.path.join(OUTPUT_DIR, \"expert1_best_model\"),  # No .h5 extension\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        save_format='tf',  # Use TensorFlow format\n",
    "        mode='min',\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    lr_scheduler = callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    early_stopping = callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return [checkpoint_cb, lr_scheduler, early_stopping]\n",
    "\n",
    "# ----------------------------\n",
    "# Training Execution\n",
    "# ----------------------------\n",
    "\n",
    "def train_expert1():\n",
    "    \"\"\"Complete training pipeline for Expert 1\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TRAINING EXPERT 1: Quantum-Enhanced PM2.5 Predictor\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create model\n",
    "    print(\"Creating Expert 1 model...\")\n",
    "    expert1 = create_expert1_model()\n",
    "    \n",
    "    print(\"\\nModel Architecture:\")\n",
    "    expert1.summary()\n",
    "    \n",
    "    # Create callbacks\n",
    "    callbacks_list = create_expert1_callbacks()\n",
    "    \n",
    "    print(f\"\\nTraining details:\")\n",
    "    print(f\"  Samples: {len(X_train)} training, {len(X_val)} validation\")\n",
    "    print(f\"  Input shape: ({SEQ_LEN}, {PATCH_SIZE}, {PATCH_SIZE}, {CHANNELS})\")\n",
    "    print(f\"  Target shape: ({PATCH_SIZE}, {PATCH_SIZE}, 1)\")\n",
    "    print(f\"  Model type: Quantum-Enhanced Sequential\")\n",
    "    print(f\"  Epochs: {EPOCHS}, Batch size: {BATCH_SIZE}\")\n",
    "    \n",
    "    # Train model\n",
    "    print(\"\\nStarting training...\")\n",
    "    history = expert1.fit(\n",
    "        X_train, y_train_pm25,\n",
    "        validation_data=(X_val, y_val_pm25),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks_list,\n",
    "        verbose=1,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"\\nTraining completed in {training_time:.2f} seconds\")\n",
    "    \n",
    "    return expert1, history, training_time  # RETURN training_time\n",
    "\n",
    "# ----------------------------\n",
    "# Evaluation\n",
    "# ----------------------------\n",
    "\n",
    "def evaluate_expert1(model, X_test, y_test):\n",
    "    \"\"\"Comprehensive evaluation of Expert 1\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EVALUATING EXPERT 1\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test, batch_size=BATCH_SIZE, verbose=1)\n",
    "    \n",
    "    # Flatten for metric calculation\n",
    "    y_true_flat = y_test.reshape(-1)\n",
    "    y_pred_flat = y_pred.reshape(-1)\n",
    "    \n",
    "    # Remove any invalid values\n",
    "    mask = ~(np.isnan(y_true_flat) | np.isnan(y_pred_flat) | np.isinf(y_true_flat) | np.isinf(y_pred_flat))\n",
    "    y_true_flat = y_true_flat[mask]\n",
    "    y_pred_flat = y_pred_flat[mask]\n",
    "    \n",
    "    # Regression metrics\n",
    "    mse = mean_squared_error(y_true_flat, y_pred_flat)\n",
    "    mae = mean_absolute_error(y_true_flat, y_pred_flat)\n",
    "    r2 = r2_score(y_true_flat, y_pred_flat)\n",
    "    \n",
    "    print(\"\\nüìä PERFORMANCE METRICS:\")\n",
    "    print(f\"  MSE:  {mse:.4f}\")\n",
    "    print(f\"  MAE:  {mae:.4f}\")\n",
    "    print(f\"  R¬≤:   {r2:.4f}\")\n",
    "    \n",
    "    # Distribution analysis\n",
    "    print(\"\\nüìà DISTRIBUTION ANALYSIS:\")\n",
    "    print(f\"  True - Min: {y_true_flat.min():.2f}, Max: {y_true_flat.max():.2f}, Mean: {y_true_flat.mean():.2f}\")\n",
    "    print(f\"  Pred - Min: {y_pred_flat.min():.2f}, Max: {y_pred_flat.max():.2f}, Mean: {y_pred_flat.mean():.2f}\")\n",
    "    \n",
    "    return {\n",
    "        'mse': mse,\n",
    "        'mae': mae, \n",
    "        'r2': r2,\n",
    "        'predictions': y_pred,\n",
    "        'y_true': y_true_flat,\n",
    "        'y_pred': y_pred_flat\n",
    "    }\n",
    "\n",
    "# ----------------------------\n",
    "# Visualization\n",
    "# ----------------------------\n",
    "\n",
    "def plot_expert1_results(history, evaluation_results):\n",
    "    \"\"\"Create visualization for Expert 1\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Loss plot\n",
    "    axes[0,0].plot(history.history['loss'], label='Training Loss')\n",
    "    axes[0,0].plot(history.history['val_loss'], label='Validation Loss')\n",
    "    axes[0,0].set_title('Expert 1: Training and Validation Loss')\n",
    "    axes[0,0].set_xlabel('Epoch')\n",
    "    axes[0,0].set_ylabel('Loss')\n",
    "    axes[0,0].legend()\n",
    "    axes[0,0].grid(True)\n",
    "    \n",
    "    # MAE plot\n",
    "    axes[0,1].plot(history.history['mae'], label='Training MAE')\n",
    "    axes[0,1].plot(history.history['val_mae'], label='Validation MAE')\n",
    "    axes[0,1].set_title('Expert 1: Training and Validation MAE')\n",
    "    axes[0,1].set_xlabel('Epoch')\n",
    "    axes[0,1].set_ylabel('MAE')\n",
    "    axes[0,1].legend()\n",
    "    axes[0,1].grid(True)\n",
    "    \n",
    "    # Prediction vs True scatter\n",
    "    y_true = evaluation_results['y_true']\n",
    "    y_pred = evaluation_results['y_pred']\n",
    "    \n",
    "    axes[1,0].scatter(y_true, y_pred, alpha=0.5, s=1)\n",
    "    axes[1,0].plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)\n",
    "    axes[1,0].set_xlabel('True PM2.5')\n",
    "    axes[1,0].set_ylabel('Predicted PM2.5')\n",
    "    axes[1,0].set_title(f'Predictions vs True (R¬≤ = {evaluation_results[\"r2\"]:.3f})')\n",
    "    axes[1,0].grid(True)\n",
    "    \n",
    "    # Error distribution\n",
    "    errors = y_pred - y_true\n",
    "    axes[1,1].hist(errors, bins=50, alpha=0.7, edgecolor='black')\n",
    "    axes[1,1].axvline(x=0, color='r', linestyle='--')\n",
    "    axes[1,1].set_xlabel('Prediction Error')\n",
    "    axes[1,1].set_ylabel('Frequency')\n",
    "    axes[1,1].set_title('Prediction Error Distribution')\n",
    "    axes[1,1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, 'expert1_results.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# ----------------------------\n",
    "# Model Saving\n",
    "# ----------------------------\n",
    "\n",
    "def save_expert1_metadata(model, history, evaluation_results, training_time):\n",
    "    \"\"\"Save metadata and model for Expert 1\"\"\"\n",
    "    \n",
    "    metadata = {\n",
    "        'expert_id': 1,\n",
    "        'expert_name': 'QuantumEnhanced_PM25_Predictor',\n",
    "        'architecture': {\n",
    "            'type': 'Quantum-Enhanced Sequential',\n",
    "            'input_shape': [SEQ_LEN, PATCH_SIZE, PATCH_SIZE, CHANNELS],\n",
    "            'output_shape': [PATCH_SIZE, PATCH_SIZE, 1],\n",
    "            'quantum_inspired': True\n",
    "        },\n",
    "        'training': {\n",
    "            'epochs_trained': len(history.history['loss']),\n",
    "            'final_train_loss': float(history.history['loss'][-1]),\n",
    "            'final_val_loss': float(history.history['val_loss'][-1]),\n",
    "            'training_time_seconds': float(training_time),\n",
    "            'batch_size': BATCH_SIZE,\n",
    "            'learning_rate': LR\n",
    "        },\n",
    "        'performance': {\n",
    "            'test_mse': float(evaluation_results['mse']),\n",
    "            'test_mae': float(evaluation_results['mae']),\n",
    "            'test_r2': float(evaluation_results['r2'])\n",
    "        },\n",
    "        'target_band': 'PM2.5',\n",
    "        'saved_format': 'TensorFlow SavedModel',\n",
    "        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "    \n",
    "    # Save metadata\n",
    "    with open(os.path.join(OUTPUT_DIR, 'expert1_metadata.json'), 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    # Save final model in TensorFlow format\n",
    "    model.save(os.path.join(OUTPUT_DIR, 'expert1_final_model'), save_format='tf')\n",
    "    \n",
    "    # Also save weights for compatibility\n",
    "    model.save_weights(os.path.join(OUTPUT_DIR, 'expert1_weights.h5'))\n",
    "    \n",
    "    print(f\"\\nüíæ Expert 1 saved successfully!\")\n",
    "    print(f\"   Model: {OUTPUT_DIR}/expert1_final_model/ (TensorFlow format)\")\n",
    "    print(f\"   Weights: {OUTPUT_DIR}/expert1_weights.h5\")\n",
    "    print(f\"   Metadata: {OUTPUT_DIR}/expert1_metadata.json\")\n",
    "\n",
    "# ----------------------------\n",
    "# Model Loading Function\n",
    "# ----------------------------\n",
    "\n",
    "def load_expert1_model():\n",
    "    \"\"\"Load trained Expert 1 model\"\"\"\n",
    "    model_path = os.path.join(OUTPUT_DIR, 'expert1_final_model')\n",
    "    if os.path.exists(model_path):\n",
    "        return tf.keras.models.load_model(model_path, custom_objects={'QuantumEnhancedLayer': QuantumEnhancedLayer})\n",
    "    else:\n",
    "        print(\"Model not found. Please train first.\")\n",
    "        return None\n",
    "\n",
    "# ----------------------------\n",
    "# Main Execution\n",
    "# ----------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üöÄ STARTING EXPERT 1: Quantum-Enhanced PM2.5 Predictor\")\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Train Expert 1\n",
    "        expert1_model, training_history, training_time = train_expert1()  # CAPTURE training_time\n",
    "        \n",
    "        # Step 2: Evaluate Expert 1\n",
    "        evaluation_results = evaluate_expert1(expert1_model, X_test, y_test_pm25)\n",
    "        \n",
    "        # Step 3: Visualize results\n",
    "        plot_expert1_results(training_history, evaluation_results)\n",
    "        \n",
    "        # Step 4: Save model and metadata\n",
    "        save_expert1_metadata(expert1_model, training_history, evaluation_results, training_time)\n",
    "        \n",
    "        print(\"\\n‚úÖ EXPERT 1 COMPLETED SUCCESSFULLY!\")\n",
    "        print(\"üìÅ Model ready for ensemble stacking!\")\n",
    "        \n",
    "        # Test loading the model\n",
    "        print(\"\\nüß™ Testing model loading...\")\n",
    "        loaded_model = load_expert1_model()\n",
    "        if loaded_model:\n",
    "            print(\"‚úÖ Model loaded successfully for ensemble integration!\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERROR in Expert 1: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbdd2c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3315f02b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
