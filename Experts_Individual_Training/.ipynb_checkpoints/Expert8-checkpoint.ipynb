{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6674be73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.10.1\n",
      "PennyLane: 0.32.0\n",
      "Loaded shapes:\n",
      " X_train: (994, 5, 10, 10, 24)\n",
      " y_train: (994, 10, 10, 7)\n",
      " X_val  : (213, 5, 10, 10, 24)\n",
      " y_val  : (213, 10, 10, 7)\n",
      " X_test : (214, 5, 10, 10, 24)\n",
      " y_test : (214, 10, 10, 7)\n",
      "PM2.5 target shapes: (994, 10, 10, 1) (213, 10, 10, 1) (214, 10, 10, 1)\n",
      "ðŸš€ STARTING EXPERT 8: Advanced Quantum-Enhanced PM2.5 Predictor\n",
      "\n",
      "============================================================\n",
      "TRAINING EXPERT 8: Advanced Quantum-Enhanced PM2.5 Predictor\n",
      "============================================================\n",
      "Creating Expert 8 model...\n",
      "\n",
      "Model Architecture:\n",
      "Model: \"Expert8_Advanced_Quantum_PM25\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 5, 10, 10,   0           []                               \n",
      "                                24)]                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 5, 10, 10, 2  96         ['input_3[0][0]']                \n",
      " rmalization)                   4)                                                                \n",
      "                                                                                                  \n",
      " time_distributed_6 (TimeDistri  (None, 5, 10, 10, 3  6944       ['batch_normalization_4[0][0]']  \n",
      " buted)                         2)                                                                \n",
      "                                                                                                  \n",
      " time_distributed_7 (TimeDistri  (None, 5, 10, 10, 6  18496      ['time_distributed_6[0][0]']     \n",
      " buted)                         4)                                                                \n",
      "                                                                                                  \n",
      " reshape_8 (Reshape)            (None, 5, 100, 24)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " time_distributed_8 (TimeDistri  (None, 5, 5, 5, 64)  0          ['time_distributed_7[0][0]']     \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " permute_2 (Permute)            (None, 100, 5, 24)   0           ['reshape_8[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling3d_2 (Gl  (None, 64)          0           ['time_distributed_8[0][0]']     \n",
      " obalAveragePooling3D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_9 (Reshape)            (None, 100, 120)     0           ['permute_2[0][0]']              \n",
      "                                                                                                  \n",
      " advanced_quantum_layer_4 (Adva  (None, 256)         98560       ['global_average_pooling3d_2[0][0\n",
      " ncedQuantumLayer)                                               ]']                              \n",
      "                                                                                                  \n",
      " temporal_attention_2 (Temporal  (None, 100, 64)     23232       ['reshape_9[0][0]']              \n",
      " Attention)                                                                                       \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 256)          0           ['advanced_quantum_layer_4[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 100, 128)     8320        ['temporal_attention_2[0][0]']   \n",
      "                                                                                                  \n",
      " advanced_quantum_layer_5 (Adva  (None, 128)         65664       ['dropout_7[0][0]']              \n",
      " ncedQuantumLayer)                                                                                \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 100, 128)     0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 6400)         825600      ['advanced_quantum_layer_5[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " reshape_10 (Reshape)           (None, 10, 10, 128)  0           ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_11 (Reshape)           (None, 10, 10, 64)   0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 10, 10, 192)  0           ['reshape_10[0][0]',             \n",
      "                                                                  'reshape_11[0][0]']             \n",
      "                                                                                                  \n",
      " spatial_attention_2 (SpatialAt  (None, 10, 10, 192)  193        ['concatenate_2[0][0]']          \n",
      " tention)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 10, 10, 128)  221312      ['spatial_attention_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 10, 10, 128)  512        ['conv2d_16[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 10, 10, 64)   73792       ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 10, 10, 64)   0           ['conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 10, 10, 32)   18464       ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 10, 10, 16)   4624        ['conv2d_18[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 10, 10, 1)    145         ['conv2d_19[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,365,954\n",
      "Trainable params: 1,365,650\n",
      "Non-trainable params: 304\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Training details:\n",
      "  Samples: 994 training, 213 validation\n",
      "  Input shape: (5, 10, 10, 24)\n",
      "  Target shape: (10, 10, 1)\n",
      "  Model type: Advanced Quantum-Enhanced with Attention\n",
      "  Epochs: 100, Batch size: 4\n",
      "  Features: Temporal Attention, Spatial Attention, Quantum Entanglement\n",
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \n",
      "Layer TemporalAttention has arguments ['units']\n",
      "in `__init__` and therefore must override `get_config()`.\n",
      "\n",
      "Example:\n",
      "\n",
      "class CustomLayer(keras.layers.Layer):\n",
      "    def __init__(self, arg1, arg2):\n",
      "        super().__init__()\n",
      "        self.arg1 = arg1\n",
      "        self.arg2 = arg2\n",
      "\n",
      "    def get_config(self):\n",
      "        config = super().get_config()\n",
      "        config.update({\n",
      "            \"arg1\": self.arg1,\n",
      "            \"arg2\": self.arg2,\n",
      "        })\n",
      "        return config\n",
      "Epoch 1/100\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.0326 - mae: 0.1321 - mse: 0.0326\n",
      "Epoch 1: val_loss improved from inf to 0.02902, saving model to C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert8_output\\expert8_best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert8_output\\expert8_best_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert8_output\\expert8_best_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/249 [==============================] - 32s 111ms/step - loss: 0.0326 - mae: 0.1321 - mse: 0.0326 - val_loss: 0.0290 - val_mae: 0.1290 - val_mse: 0.0290 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.0114 - mae: 0.0806 - mse: 0.0114\n",
      "Epoch 2: val_loss improved from 0.02902 to 0.00681, saving model to C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert8_output\\expert8_best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert8_output\\expert8_best_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert8_output\\expert8_best_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/249 [==============================] - 26s 105ms/step - loss: 0.0114 - mae: 0.0806 - mse: 0.0114 - val_loss: 0.0068 - val_mae: 0.0670 - val_mse: 0.0068 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "248/249 [============================>.] - ETA: 0s - loss: 0.0053 - mae: 0.0539 - mse: 0.0053\n",
      "Epoch 3: val_loss improved from 0.00681 to 0.00279, saving model to C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert8_output\\expert8_best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert8_output\\expert8_best_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert8_output\\expert8_best_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/249 [==============================] - 26s 105ms/step - loss: 0.0053 - mae: 0.0539 - mse: 0.0053 - val_loss: 0.0028 - val_mae: 0.0361 - val_mse: 0.0028 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.0029 - mae: 0.0413 - mse: 0.0029\n",
      "Epoch 4: val_loss improved from 0.00279 to 0.00209, saving model to C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert8_output\\expert8_best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert8_output\\expert8_best_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert8_output\\expert8_best_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/249 [==============================] - 26s 104ms/step - loss: 0.0029 - mae: 0.0413 - mse: 0.0029 - val_loss: 0.0021 - val_mae: 0.0297 - val_mse: 0.0021 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "248/249 [============================>.] - ETA: 0s - loss: 0.0022 - mae: 0.0354 - mse: 0.0022\n",
      "Epoch 5: val_loss did not improve from 0.00209\n",
      "249/249 [==============================] - 19s 76ms/step - loss: 0.0022 - mae: 0.0354 - mse: 0.0022 - val_loss: 0.0044 - val_mae: 0.0351 - val_mse: 0.0044 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "248/249 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0329 - mse: 0.0019\n",
      "Epoch 6: val_loss improved from 0.00209 to 0.00080, saving model to C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert8_output\\expert8_best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert8_output\\expert8_best_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert8_output\\expert8_best_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/249 [==============================] - 25s 101ms/step - loss: 0.0019 - mae: 0.0329 - mse: 0.0019 - val_loss: 8.0461e-04 - val_mae: 0.0221 - val_mse: 8.0461e-04 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "248/249 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0321 - mse: 0.0019\n",
      "Epoch 7: val_loss did not improve from 0.00080\n",
      "249/249 [==============================] - 19s 76ms/step - loss: 0.0019 - mae: 0.0321 - mse: 0.0019 - val_loss: 0.0026 - val_mae: 0.0305 - val_mse: 0.0026 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "248/249 [============================>.] - ETA: 0s - loss: 0.0012 - mae: 0.0265 - mse: 0.0012\n",
      "Epoch 8: val_loss did not improve from 0.00080\n",
      "249/249 [==============================] - 20s 79ms/step - loss: 0.0012 - mae: 0.0265 - mse: 0.0012 - val_loss: 0.0015 - val_mae: 0.0248 - val_mse: 0.0015 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.0016 - mae: 0.0298 - mse: 0.0016\n",
      "Epoch 9: val_loss did not improve from 0.00080\n",
      "249/249 [==============================] - 18s 72ms/step - loss: 0.0016 - mae: 0.0298 - mse: 0.0016 - val_loss: 0.0020 - val_mae: 0.0322 - val_mse: 0.0020 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0263 - mse: 0.0012\n",
      "Epoch 10: val_loss did not improve from 0.00080\n",
      "249/249 [==============================] - 18s 74ms/step - loss: 0.0012 - mae: 0.0263 - mse: 0.0012 - val_loss: 0.0030 - val_mae: 0.0307 - val_mse: 0.0030 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "248/249 [============================>.] - ETA: 0s - loss: 0.0011 - mae: 0.0253 - mse: 0.0011\n",
      "Epoch 11: val_loss did not improve from 0.00080\n",
      "249/249 [==============================] - 18s 74ms/step - loss: 0.0011 - mae: 0.0254 - mse: 0.0011 - val_loss: 0.0010 - val_mae: 0.0206 - val_mse: 0.0010 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "248/249 [============================>.] - ETA: 0s - loss: 0.0012 - mae: 0.0261 - mse: 0.0012\n",
      "Epoch 12: val_loss did not improve from 0.00080\n",
      "249/249 [==============================] - 19s 75ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0012 - val_loss: 0.0012 - val_mae: 0.0246 - val_mse: 0.0012 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "249/249 [==============================] - ETA: 0s - loss: 0.0016 - mae: 0.0280 - mse: 0.0016\n",
      "Epoch 13: val_loss did not improve from 0.00080\n",
      "249/249 [==============================] - 20s 79ms/step - loss: 0.0016 - mae: 0.0280 - mse: 0.0016 - val_loss: 0.0014 - val_mae: 0.0241 - val_mse: 0.0014 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "248/249 [============================>.] - ETA: 0s - loss: 9.7113e-04 - mae: 0.0232 - mse: 9.7113e-04\n",
      "Epoch 14: val_loss did not improve from 0.00080\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "249/249 [==============================] - 18s 74ms/step - loss: 9.7070e-04 - mae: 0.0231 - mse: 9.7070e-04 - val_loss: 0.0065 - val_mae: 0.0431 - val_mse: 0.0065 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "248/249 [============================>.] - ETA: 0s - loss: 6.5551e-04 - mae: 0.0191 - mse: 6.5551e-04\n",
      "Epoch 15: val_loss did not improve from 0.00080\n",
      "249/249 [==============================] - 18s 73ms/step - loss: 6.5821e-04 - mae: 0.0192 - mse: 6.5821e-04 - val_loss: 0.0027 - val_mae: 0.0308 - val_mse: 0.0027 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "248/249 [============================>.] - ETA: 0s - loss: 6.7450e-04 - mae: 0.0190 - mse: 6.7450e-04\n",
      "Epoch 16: val_loss improved from 0.00080 to 0.00078, saving model to C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert8_output\\expert8_best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert8_output\\expert8_best_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert8_output\\expert8_best_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/249 [==============================] - 28s 110ms/step - loss: 6.7521e-04 - mae: 0.0191 - mse: 6.7521e-04 - val_loss: 7.8159e-04 - val_mae: 0.0194 - val_mse: 7.8159e-04 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "248/249 [============================>.] - ETA: 0s - loss: 6.2473e-04 - mae: 0.0184 - mse: 6.2473e-04\n",
      "Epoch 17: val_loss did not improve from 0.00078\n",
      "249/249 [==============================] - 19s 76ms/step - loss: 6.2479e-04 - mae: 0.0184 - mse: 6.2479e-04 - val_loss: 0.0011 - val_mae: 0.0217 - val_mse: 0.0011 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "248/249 [============================>.] - ETA: 0s - loss: 5.7349e-04 - mae: 0.0177 - mse: 5.7349e-04\n",
      "Epoch 18: val_loss did not improve from 0.00078\n",
      "249/249 [==============================] - 18s 72ms/step - loss: 5.7334e-04 - mae: 0.0177 - mse: 5.7334e-04 - val_loss: 0.0023 - val_mae: 0.0237 - val_mse: 0.0023 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "248/249 [============================>.] - ETA: 0s - loss: 5.1222e-04 - mae: 0.0165 - mse: 5.1222e-04\n",
      "Epoch 19: val_loss did not improve from 0.00078\n",
      "249/249 [==============================] - 19s 75ms/step - loss: 5.1217e-04 - mae: 0.0165 - mse: 5.1217e-04 - val_loss: 0.0012 - val_mae: 0.0195 - val_mse: 0.0012 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "248/249 [============================>.] - ETA: 0s - loss: 6.4156e-04 - mae: 0.0184 - mse: 6.4156e-04\n",
      "Epoch 20: val_loss did not improve from 0.00078\n",
      "249/249 [==============================] - 19s 75ms/step - loss: 6.4055e-04 - mae: 0.0183 - mse: 6.4056e-04 - val_loss: 0.0028 - val_mae: 0.0270 - val_mse: 0.0028 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "248/249 [============================>.] - ETA: 0s - loss: 7.7735e-04 - mae: 0.0202 - mse: 7.7735e-04\n",
      "Epoch 21: val_loss did not improve from 0.00078\n",
      "249/249 [==============================] - 18s 73ms/step - loss: 7.7624e-04 - mae: 0.0202 - mse: 7.7624e-04 - val_loss: 0.0032 - val_mae: 0.0242 - val_mse: 0.0032 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "248/249 [============================>.] - ETA: 0s - loss: 6.5766e-04 - mae: 0.0185 - mse: 6.5766e-04\n",
      "Epoch 22: val_loss did not improve from 0.00078\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "249/249 [==============================] - 19s 75ms/step - loss: 6.5669e-04 - mae: 0.0185 - mse: 6.5669e-04 - val_loss: 0.0016 - val_mae: 0.0237 - val_mse: 0.0016 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "248/249 [============================>.] - ETA: 0s - loss: 4.5673e-04 - mae: 0.0153 - mse: 4.5673e-04\n",
      "Epoch 23: val_loss did not improve from 0.00078\n",
      "249/249 [==============================] - 19s 74ms/step - loss: 4.5595e-04 - mae: 0.0153 - mse: 4.5595e-04 - val_loss: 0.0013 - val_mae: 0.0174 - val_mse: 0.0013 - lr: 2.5000e-04\n",
      "Epoch 24/100\n",
      "248/249 [============================>.] - ETA: 0s - loss: 3.9454e-04 - mae: 0.0145 - mse: 3.9454e-04\n",
      "Epoch 24: val_loss did not improve from 0.00078\n",
      "249/249 [==============================] - 19s 76ms/step - loss: 3.9414e-04 - mae: 0.0145 - mse: 3.9414e-04 - val_loss: 0.0012 - val_mae: 0.0176 - val_mse: 0.0012 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "248/249 [============================>.] - ETA: 0s - loss: 4.4571e-04 - mae: 0.0151 - mse: 4.4571e-04\n",
      "Epoch 25: val_loss did not improve from 0.00078\n",
      "249/249 [==============================] - 19s 74ms/step - loss: 4.4815e-04 - mae: 0.0151 - mse: 4.4815e-04 - val_loss: 9.2091e-04 - val_mae: 0.0153 - val_mse: 9.2091e-04 - lr: 2.5000e-04\n",
      "Epoch 26/100\n",
      "249/249 [==============================] - ETA: 0s - loss: 4.4120e-04 - mae: 0.0153 - mse: 4.4120e-04\n",
      "Epoch 26: val_loss did not improve from 0.00078\n",
      "249/249 [==============================] - 19s 77ms/step - loss: 4.4120e-04 - mae: 0.0153 - mse: 4.4120e-04 - val_loss: 9.9468e-04 - val_mae: 0.0181 - val_mse: 9.9468e-04 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "248/249 [============================>.] - ETA: 0s - loss: 3.8354e-04 - mae: 0.0141 - mse: 3.8354e-04\n",
      "Epoch 27: val_loss did not improve from 0.00078\n",
      "249/249 [==============================] - 19s 75ms/step - loss: 3.8322e-04 - mae: 0.0141 - mse: 3.8322e-04 - val_loss: 0.0010 - val_mae: 0.0153 - val_mse: 0.0010 - lr: 2.5000e-04\n",
      "Epoch 28/100\n",
      "248/249 [============================>.] - ETA: 0s - loss: 3.6538e-04 - mae: 0.0139 - mse: 3.6538e-04\n",
      "Epoch 28: val_loss did not improve from 0.00078\n",
      "249/249 [==============================] - 18s 74ms/step - loss: 3.6510e-04 - mae: 0.0139 - mse: 3.6510e-04 - val_loss: 8.5891e-04 - val_mae: 0.0170 - val_mse: 8.5891e-04 - lr: 2.5000e-04\n",
      "Epoch 29/100\n",
      "248/249 [============================>.] - ETA: 0s - loss: 4.2778e-04 - mae: 0.0150 - mse: 4.2778e-04\n",
      "Epoch 29: val_loss did not improve from 0.00078\n",
      "249/249 [==============================] - 19s 75ms/step - loss: 4.2909e-04 - mae: 0.0150 - mse: 4.2909e-04 - val_loss: 9.5461e-04 - val_mae: 0.0160 - val_mse: 9.5461e-04 - lr: 2.5000e-04\n",
      "Epoch 30/100\n",
      "248/249 [============================>.] - ETA: 0s - loss: 3.7843e-04 - mae: 0.0142 - mse: 3.7843e-04\n",
      "Epoch 30: val_loss improved from 0.00078 to 0.00046, saving model to C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert8_output\\expert8_best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert8_output\\expert8_best_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert8_output\\expert8_best_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/249 [==============================] - 27s 107ms/step - loss: 3.7784e-04 - mae: 0.0142 - mse: 3.7784e-04 - val_loss: 4.6490e-04 - val_mae: 0.0117 - val_mse: 4.6490e-04 - lr: 2.5000e-04\n",
      "Epoch 31/100\n",
      "248/249 [============================>.] - ETA: 0s - loss: 3.6738e-04 - mae: 0.0140 - mse: 3.6738e-04\n",
      "Epoch 31: val_loss did not improve from 0.00046\n",
      "249/249 [==============================] - 20s 81ms/step - loss: 3.6737e-04 - mae: 0.0140 - mse: 3.6737e-04 - val_loss: 5.0006e-04 - val_mae: 0.0128 - val_mse: 5.0006e-04 - lr: 2.5000e-04\n",
      "Epoch 32/100\n",
      "249/249 [==============================] - ETA: 0s - loss: 3.6407e-04 - mae: 0.0139 - mse: 3.6407e-04\n",
      "Epoch 32: val_loss did not improve from 0.00046\n",
      "249/249 [==============================] - 21s 85ms/step - loss: 3.6407e-04 - mae: 0.0139 - mse: 3.6407e-04 - val_loss: 0.0013 - val_mae: 0.0173 - val_mse: 0.0013 - lr: 2.5000e-04\n",
      "Epoch 33/100\n",
      "248/249 [============================>.] - ETA: 0s - loss: 4.0265e-04 - mae: 0.0146 - mse: 4.0264e-04\n",
      "Epoch 33: val_loss did not improve from 0.00046\n",
      "249/249 [==============================] - 19s 77ms/step - loss: 4.0233e-04 - mae: 0.0146 - mse: 4.0233e-04 - val_loss: 0.0015 - val_mae: 0.0194 - val_mse: 0.0015 - lr: 2.5000e-04\n",
      "Epoch 34/100\n",
      "248/249 [============================>.] - ETA: 0s - loss: 4.3092e-04 - mae: 0.0151 - mse: 4.3092e-04\n",
      "Epoch 34: val_loss did not improve from 0.00046\n",
      "249/249 [==============================] - 18s 73ms/step - loss: 4.3226e-04 - mae: 0.0151 - mse: 4.3226e-04 - val_loss: 0.0027 - val_mae: 0.0212 - val_mse: 0.0027 - lr: 2.5000e-04\n",
      "Epoch 35/100\n",
      "249/249 [==============================] - ETA: 0s - loss: 3.3352e-04 - mae: 0.0133 - mse: 3.3352e-04\n",
      "Epoch 35: val_loss did not improve from 0.00046\n",
      "249/249 [==============================] - 20s 82ms/step - loss: 3.3352e-04 - mae: 0.0133 - mse: 3.3352e-04 - val_loss: 9.2056e-04 - val_mae: 0.0155 - val_mse: 9.2056e-04 - lr: 2.5000e-04\n",
      "Epoch 36/100\n",
      "248/249 [============================>.] - ETA: 0s - loss: 4.5413e-04 - mae: 0.0152 - mse: 4.5413e-04\n",
      "Epoch 36: val_loss did not improve from 0.00046\n",
      "249/249 [==============================] - 26s 104ms/step - loss: 4.5358e-04 - mae: 0.0152 - mse: 4.5358e-04 - val_loss: 0.0019 - val_mae: 0.0200 - val_mse: 0.0019 - lr: 2.5000e-04\n",
      "Epoch 37/100\n",
      "248/249 [============================>.] - ETA: 0s - loss: 4.9493e-04 - mae: 0.0156 - mse: 4.9493e-04\n",
      "Epoch 37: val_loss did not improve from 0.00046\n",
      "249/249 [==============================] - 20s 81ms/step - loss: 4.9408e-04 - mae: 0.0156 - mse: 4.9408e-04 - val_loss: 9.0438e-04 - val_mae: 0.0171 - val_mse: 9.0438e-04 - lr: 2.5000e-04\n",
      "Epoch 38/100\n",
      " 23/249 [=>............................] - ETA: 19s - loss: 3.9623e-04 - mae: 0.0147 - mse: 3.9623e-04"
     ]
    }
   ],
   "source": [
    "# Expert 8: Advanced Quantum-Enhanced PM2.5 Predictor\n",
    "# Using TensorFlow SavedModel format for subclassed models\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''  # comment out to enable GPU\n",
    "\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, optimizers, callbacks\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----------------------------\n",
    "# CONFIG\n",
    "# ----------------------------\n",
    "DATA_DIR = r\"C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\datasets\"\n",
    "OUTPUT_DIR = r\"C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\models\\expert8_output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "SEQ_LEN = 5\n",
    "PATCH_SIZE = 10\n",
    "CHANNELS = 24\n",
    "PRED_BAND_IDX = 0\n",
    "NUM_QUBITS = 4\n",
    "Q_DEPTH = 2\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 4\n",
    "LR = 1e-3\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"PennyLane:\", qml.__version__)\n",
    "\n",
    "# ----------------------------\n",
    "# Load datasets\n",
    "# ----------------------------\n",
    "\n",
    "def load_npy(name):\n",
    "    path = os.path.join(DATA_DIR, name)\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(path)\n",
    "    return np.load(path)\n",
    "\n",
    "X_train = load_npy(\"X_train.npy\")\n",
    "y_train = load_npy(\"y_train.npy\")\n",
    "X_val = load_npy(\"X_val.npy\")\n",
    "y_val = load_npy(\"y_val.npy\")\n",
    "X_test = load_npy(\"X_test.npy\")\n",
    "y_test = load_npy(\"y_test.npy\")\n",
    "\n",
    "print(\"Loaded shapes:\")\n",
    "print(\" X_train:\", X_train.shape)\n",
    "print(\" y_train:\", y_train.shape)\n",
    "print(\" X_val  :\", X_val.shape)\n",
    "print(\" y_val  :\", y_val.shape)\n",
    "print(\" X_test :\", X_test.shape)\n",
    "print(\" y_test :\", y_test.shape)\n",
    "\n",
    "# Prepare PM2.5 targets\n",
    "def extract_pm25(y):\n",
    "    pm25 = y[..., PRED_BAND_IDX]\n",
    "    return pm25[..., None].astype(np.float32)\n",
    "\n",
    "y_train_pm25 = extract_pm25(y_train)\n",
    "y_val_pm25 = extract_pm25(y_val)\n",
    "y_test_pm25 = extract_pm25(y_test)\n",
    "\n",
    "print(\"PM2.5 target shapes:\", y_train_pm25.shape, y_val_pm25.shape, y_test_pm25.shape)\n",
    "\n",
    "# ----------------------------\n",
    "# Advanced Quantum-Enhanced Layer\n",
    "# ----------------------------\n",
    "\n",
    "class AdvancedQuantumLayer(layers.Layer):\n",
    "    \"\"\"Advanced quantum-inspired layer with entanglement simulation\"\"\"\n",
    "    \n",
    "    def __init__(self, units, use_entanglement=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.use_entanglement = use_entanglement\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        # Quantum-inspired weights with complex representation\n",
    "        self.quantum_weights_real = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer='glorot_uniform',\n",
    "            trainable=True,\n",
    "            name='quantum_weights_real'\n",
    "        )\n",
    "        self.quantum_weights_imag = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer='glorot_uniform',\n",
    "            trainable=True,\n",
    "            name='quantum_weights_imag'\n",
    "        )\n",
    "        \n",
    "        # Entanglement simulation weights\n",
    "        if self.use_entanglement:\n",
    "            self.entanglement_weights = self.add_weight(\n",
    "                shape=(self.units, self.units),\n",
    "                initializer='orthogonal',\n",
    "                trainable=True,\n",
    "                name='entanglement_weights'\n",
    "            )\n",
    "        \n",
    "        self.bias = self.add_weight(\n",
    "            shape=(self.units,),\n",
    "            initializer='zeros',\n",
    "            trainable=True,\n",
    "            name='bias'\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # Quantum-inspired transformation with complex operations\n",
    "        real_part = tf.matmul(inputs, self.quantum_weights_real)\n",
    "        imag_part = tf.matmul(inputs, self.quantum_weights_imag)\n",
    "        \n",
    "        # Quantum probability amplitude\n",
    "        magnitude = tf.sqrt(real_part**2 + imag_part**2 + 1e-8)\n",
    "        \n",
    "        # Entanglement simulation\n",
    "        if self.use_entanglement:\n",
    "            entangled = tf.matmul(magnitude, self.entanglement_weights)\n",
    "            magnitude = 0.7 * magnitude + 0.3 * entangled\n",
    "        \n",
    "        # Quantum-inspired activation\n",
    "        output = magnitude + self.bias\n",
    "        return tf.nn.swish(output)  # Smooth activation\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"units\": self.units,\n",
    "            \"use_entanglement\": self.use_entanglement\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# ----------------------------\n",
    "# Attention Mechanisms\n",
    "# ----------------------------\n",
    "\n",
    "class TemporalAttention(layers.Layer):\n",
    "    \"\"\"Temporal attention for sequence processing\"\"\"\n",
    "    \n",
    "    def __init__(self, units, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.query = layers.Dense(self.units)\n",
    "        self.key = layers.Dense(self.units)\n",
    "        self.value = layers.Dense(self.units)\n",
    "        super().build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # inputs shape: (batch, seq_len, features)\n",
    "        q = self.query(inputs)\n",
    "        k = self.key(inputs)\n",
    "        v = self.value(inputs)\n",
    "        \n",
    "        # Scaled dot-product attention\n",
    "        scores = tf.matmul(q, k, transpose_b=True)\n",
    "        scores = scores / tf.math.sqrt(tf.cast(self.units, tf.float32))\n",
    "        attention_weights = tf.nn.softmax(scores, axis=-1)\n",
    "        \n",
    "        # Apply attention\n",
    "        output = tf.matmul(attention_weights, v)\n",
    "        return output\n",
    "\n",
    "class SpatialAttention(layers.Layer):\n",
    "    \"\"\"Spatial attention for patch processing\"\"\"\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.conv1 = layers.Conv2D(1, 1, activation='sigmoid')\n",
    "        super().build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # inputs shape: (batch, height, width, channels)\n",
    "        attention_weights = self.conv1(inputs)\n",
    "        return inputs * attention_weights\n",
    "\n",
    "# ----------------------------\n",
    "# Expert 8 Model Architecture\n",
    "# ----------------------------\n",
    "\n",
    "def create_expert8_advanced_quantum():\n",
    "    \"\"\"Expert 8 with advanced quantum-enhanced architecture\"\"\"\n",
    "    \n",
    "    inputs = layers.Input(shape=(SEQ_LEN, PATCH_SIZE, PATCH_SIZE, CHANNELS))\n",
    "    \n",
    "    # Initial processing\n",
    "    x = layers.BatchNormalization()(inputs)\n",
    "    \n",
    "    # Temporal processing branch\n",
    "    temporal_branch = layers.TimeDistributed(\n",
    "        layers.Conv2D(32, 3, activation='relu', padding='same')\n",
    "    )(x)\n",
    "    temporal_branch = layers.TimeDistributed(\n",
    "        layers.Conv2D(64, 3, activation='relu', padding='same')\n",
    "    )(temporal_branch)\n",
    "    temporal_branch = layers.TimeDistributed(\n",
    "        layers.MaxPooling2D(2)\n",
    "    )(temporal_branch)  # Output: (batch, seq_len, 5, 5, 64)\n",
    "    \n",
    "    # Spatial processing branch\n",
    "    spatial_branch = layers.Reshape((SEQ_LEN, PATCH_SIZE * PATCH_SIZE, CHANNELS))(x)\n",
    "    spatial_branch = layers.Permute((2, 1, 3))(spatial_branch)  # (batch, 100, 5, 24)\n",
    "    spatial_branch = layers.Reshape((PATCH_SIZE * PATCH_SIZE, SEQ_LEN * CHANNELS))(spatial_branch)  # (batch, 100, 120)\n",
    "    \n",
    "    # Apply temporal attention\n",
    "    temporal_attention = TemporalAttention(units=64)(spatial_branch)\n",
    "    temporal_attention = layers.Dense(128, activation='relu')(temporal_attention)\n",
    "    temporal_attention = layers.Dropout(0.3)(temporal_attention)\n",
    "    \n",
    "    # Reshape back to spatial dimensions\n",
    "    temporal_attention = layers.Reshape((PATCH_SIZE, PATCH_SIZE, 128))(temporal_attention)\n",
    "    \n",
    "    # Advanced quantum-enhanced processing\n",
    "    quantum_features = layers.GlobalAveragePooling3D()(temporal_branch)\n",
    "    quantum_features = AdvancedQuantumLayer(256, use_entanglement=True)(quantum_features)\n",
    "    quantum_features = layers.Dropout(0.2)(quantum_features)\n",
    "    quantum_features = AdvancedQuantumLayer(128, use_entanglement=False)(quantum_features)\n",
    "    \n",
    "    # Expand quantum features to spatial dimensions\n",
    "    quantum_expanded = layers.Dense(PATCH_SIZE * PATCH_SIZE * 64)(quantum_features)\n",
    "    quantum_expanded = layers.Reshape((PATCH_SIZE, PATCH_SIZE, 64))(quantum_expanded)\n",
    "    \n",
    "    # Combine branches\n",
    "    combined = layers.Concatenate()([temporal_attention, quantum_expanded])\n",
    "    \n",
    "    # Spatial attention\n",
    "    combined = SpatialAttention()(combined)\n",
    "    \n",
    "    # Refinement layers\n",
    "    x = layers.Conv2D(128, 3, activation='relu', padding='same')(combined)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.Conv2D(16, 3, activation='relu', padding='same')(x)\n",
    "    \n",
    "    # Final output\n",
    "    outputs = layers.Conv2D(1, 3, activation='linear', padding='same')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs, name=\"Expert8_Advanced_Quantum_PM25\")\n",
    "    return model\n",
    "\n",
    "# ----------------------------\n",
    "# Training Setup\n",
    "# ----------------------------\n",
    "\n",
    "def create_expert8_model():\n",
    "    \"\"\"Create Expert 8 model\"\"\"\n",
    "    model = create_expert8_advanced_quantum()\n",
    "    \n",
    "    # Use standard Adam optimizer instead of AdamW\n",
    "    optimizer = optimizers.Adam(learning_rate=LR)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='mse',\n",
    "        metrics=['mae', 'mse']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_expert8_callbacks():\n",
    "    \"\"\"Create callbacks for training Expert 8\"\"\"\n",
    "    \n",
    "    checkpoint_cb = callbacks.ModelCheckpoint(\n",
    "        os.path.join(OUTPUT_DIR, \"expert8_best_model\"),\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        save_format='tf',\n",
    "        mode='min',\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    lr_scheduler = callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    early_stopping = callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    tensorboard = callbacks.TensorBoard(\n",
    "        log_dir=os.path.join(OUTPUT_DIR, 'logs'),\n",
    "        update_freq='epoch'\n",
    "    )\n",
    "    \n",
    "    return [checkpoint_cb, lr_scheduler, early_stopping, tensorboard]\n",
    "\n",
    "# ----------------------------\n",
    "# Training Execution\n",
    "# ----------------------------\n",
    "\n",
    "def train_expert8():\n",
    "    \"\"\"Complete training pipeline for Expert 8\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TRAINING EXPERT 8: Advanced Quantum-Enhanced PM2.5 Predictor\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create model\n",
    "    print(\"Creating Expert 8 model...\")\n",
    "    expert8 = create_expert8_model()\n",
    "    \n",
    "    print(\"\\nModel Architecture:\")\n",
    "    expert8.summary()\n",
    "    \n",
    "    # Create callbacks\n",
    "    callbacks_list = create_expert8_callbacks()\n",
    "    \n",
    "    print(f\"\\nTraining details:\")\n",
    "    print(f\"  Samples: {len(X_train)} training, {len(X_val)} validation\")\n",
    "    print(f\"  Input shape: ({SEQ_LEN}, {PATCH_SIZE}, {PATCH_SIZE}, {CHANNELS})\")\n",
    "    print(f\"  Target shape: ({PATCH_SIZE}, {PATCH_SIZE}, 1)\")\n",
    "    print(f\"  Model type: Advanced Quantum-Enhanced with Attention\")\n",
    "    print(f\"  Epochs: {EPOCHS}, Batch size: {BATCH_SIZE}\")\n",
    "    print(f\"  Features: Temporal Attention, Spatial Attention, Quantum Entanglement\")\n",
    "    \n",
    "    # Train model\n",
    "    print(\"\\nStarting training...\")\n",
    "    history = expert8.fit(\n",
    "        X_train, y_train_pm25,\n",
    "        validation_data=(X_val, y_val_pm25),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks_list,\n",
    "        verbose=1,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"\\nTraining completed in {training_time:.2f} seconds\")\n",
    "    \n",
    "    return expert8, history, training_time\n",
    "\n",
    "# ----------------------------\n",
    "# Evaluation\n",
    "# ----------------------------\n",
    "\n",
    "def evaluate_expert8(model, X_test, y_test):\n",
    "    \"\"\"Comprehensive evaluation of Expert 8\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EVALUATING EXPERT 8\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test, batch_size=BATCH_SIZE, verbose=1)\n",
    "    \n",
    "    # Flatten for metric calculation\n",
    "    y_true_flat = y_test.reshape(-1)\n",
    "    y_pred_flat = y_pred.reshape(-1)\n",
    "    \n",
    "    # Remove any invalid values\n",
    "    mask = ~(np.isnan(y_true_flat) | np.isnan(y_pred_flat) | np.isinf(y_true_flat) | np.isinf(y_pred_flat))\n",
    "    y_true_flat = y_true_flat[mask]\n",
    "    y_pred_flat = y_pred_flat[mask]\n",
    "    \n",
    "    # Regression metrics\n",
    "    mse = mean_squared_error(y_true_flat, y_pred_flat)\n",
    "    mae = mean_absolute_error(y_true_flat, y_pred_flat)\n",
    "    r2 = r2_score(y_true_flat, y_pred_flat)\n",
    "    \n",
    "    print(\"\\nðŸ“Š PERFORMANCE METRICS:\")\n",
    "    print(f\"  MSE:  {mse:.4f}\")\n",
    "    print(f\"  MAE:  {mae:.4f}\")\n",
    "    print(f\"  RÂ²:   {r2:.4f}\")\n",
    "    \n",
    "    # Distribution analysis\n",
    "    print(\"\\nðŸ“ˆ DISTRIBUTION ANALYSIS:\")\n",
    "    print(f\"  True - Min: {y_true_flat.min():.2f}, Max: {y_true_flat.max():.2f}, Mean: {y_true_flat.mean():.2f}\")\n",
    "    print(f\"  Pred - Min: {y_pred_flat.min():.2f}, Max: {y_pred_flat.max():.2f}, Mean: {y_pred_flat.mean():.2f}\")\n",
    "    \n",
    "    return {\n",
    "        'mse': mse,\n",
    "        'mae': mae, \n",
    "        'r2': r2,\n",
    "        'predictions': y_pred,\n",
    "        'y_true': y_true_flat,\n",
    "        'y_pred': y_pred_flat\n",
    "    }\n",
    "\n",
    "# ----------------------------\n",
    "# Visualization\n",
    "# ----------------------------\n",
    "\n",
    "def plot_expert8_results(history, evaluation_results):\n",
    "    \"\"\"Create visualization for Expert 8\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Loss plot\n",
    "    axes[0,0].plot(history.history['loss'], label='Training Loss')\n",
    "    axes[0,0].plot(history.history['val_loss'], label='Validation Loss')\n",
    "    axes[0,0].set_title('Expert 8: Training and Validation Loss')\n",
    "    axes[0,0].set_xlabel('Epoch')\n",
    "    axes[0,0].set_ylabel('Loss')\n",
    "    axes[0,0].legend()\n",
    "    axes[0,0].grid(True)\n",
    "    \n",
    "    # MAE plot\n",
    "    axes[0,1].plot(history.history['mae'], label='Training MAE')\n",
    "    axes[0,1].plot(history.history['val_mae'], label='Validation MAE')\n",
    "    axes[0,1].set_title('Expert 8: Training and Validation MAE')\n",
    "    axes[0,1].set_xlabel('Epoch')\n",
    "    axes[0,1].set_ylabel('MAE')\n",
    "    axes[0,1].legend()\n",
    "    axes[0,1].grid(True)\n",
    "    \n",
    "    # Prediction vs True scatter\n",
    "    y_true = evaluation_results['y_true']\n",
    "    y_pred = evaluation_results['y_pred']\n",
    "    \n",
    "    axes[1,0].scatter(y_true, y_pred, alpha=0.5, s=1)\n",
    "    axes[1,0].plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)\n",
    "    axes[1,0].set_xlabel('True PM2.5')\n",
    "    axes[1,0].set_ylabel('Predicted PM2.5')\n",
    "    axes[1,0].set_title(f'Predictions vs True (RÂ² = {evaluation_results[\"r2\"]:.3f})')\n",
    "    axes[1,0].grid(True)\n",
    "    \n",
    "    # Error distribution\n",
    "    errors = y_pred - y_true\n",
    "    axes[1,1].hist(errors, bins=50, alpha=0.7, edgecolor='black')\n",
    "    axes[1,1].axvline(x=0, color='r', linestyle='--')\n",
    "    axes[1,1].set_xlabel('Prediction Error')\n",
    "    axes[1,1].set_ylabel('Frequency')\n",
    "    axes[1,1].set_title('Prediction Error Distribution')\n",
    "    axes[1,1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, 'expert8_results.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# ----------------------------\n",
    "# Model Saving\n",
    "# ----------------------------\n",
    "\n",
    "def save_expert8_metadata(model, history, evaluation_results, training_time):\n",
    "    \"\"\"Save metadata and model for Expert 8\"\"\"\n",
    "    \n",
    "    metadata = {\n",
    "        'expert_id': 8,\n",
    "        'expert_name': 'Advanced_Quantum_Enhanced_PM25_Predictor',\n",
    "        'architecture': {\n",
    "            'type': 'Advanced Quantum-Enhanced with Attention',\n",
    "            'input_shape': [SEQ_LEN, PATCH_SIZE, PATCH_SIZE, CHANNELS],\n",
    "            'output_shape': [PATCH_SIZE, PATCH_SIZE, 1],\n",
    "            'features': ['Temporal Attention', 'Spatial Attention', 'Quantum Entanglement', 'Advanced Quantum Layers']\n",
    "        },\n",
    "        'training': {\n",
    "            'epochs_trained': len(history.history['loss']),\n",
    "            'final_train_loss': float(history.history['loss'][-1]),\n",
    "            'final_val_loss': float(history.history['val_loss'][-1]),\n",
    "            'training_time_seconds': float(training_time),\n",
    "            'batch_size': BATCH_SIZE,\n",
    "            'learning_rate': LR\n",
    "        },\n",
    "        'performance': {\n",
    "            'test_mse': float(evaluation_results['mse']),\n",
    "            'test_mae': float(evaluation_results['mae']),\n",
    "            'test_r2': float(evaluation_results['r2'])\n",
    "        },\n",
    "        'target_band': 'PM2.5',\n",
    "        'saved_format': 'TensorFlow SavedModel',\n",
    "        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "    \n",
    "    # Save metadata\n",
    "    with open(os.path.join(OUTPUT_DIR, 'expert8_metadata.json'), 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    # Save final model in TensorFlow format\n",
    "    model.save(os.path.join(OUTPUT_DIR, 'expert8_final_model'), save_format='tf')\n",
    "    \n",
    "    # Also save weights for compatibility\n",
    "    model.save_weights(os.path.join(OUTPUT_DIR, 'expert8_weights.h5'))\n",
    "    \n",
    "    print(f\"\\nðŸ’¾ Expert 8 saved successfully!\")\n",
    "    print(f\"   Model: {OUTPUT_DIR}/expert8_final_model/ (TensorFlow format)\")\n",
    "    print(f\"   Weights: {OUTPUT_DIR}/expert8_weights.h5\")\n",
    "    print(f\"   Metadata: {OUTPUT_DIR}/expert8_metadata.json\")\n",
    "\n",
    "# ----------------------------\n",
    "# Model Loading Function\n",
    "# ----------------------------\n",
    "\n",
    "def load_expert8_model():\n",
    "    \"\"\"Load trained Expert 8 model\"\"\"\n",
    "    model_path = os.path.join(OUTPUT_DIR, 'expert8_final_model')\n",
    "    if os.path.exists(model_path):\n",
    "        return tf.keras.models.load_model(\n",
    "            model_path, \n",
    "            custom_objects={\n",
    "                'AdvancedQuantumLayer': AdvancedQuantumLayer,\n",
    "                'TemporalAttention': TemporalAttention,\n",
    "                'SpatialAttention': SpatialAttention\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        print(\"Model not found. Please train first.\")\n",
    "        return None\n",
    "\n",
    "# ----------------------------\n",
    "# Main Execution\n",
    "# ----------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ðŸš€ STARTING EXPERT 8: Advanced Quantum-Enhanced PM2.5 Predictor\")\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Train Expert 8\n",
    "        expert8_model, training_history, training_time = train_expert8()\n",
    "        \n",
    "        # Step 2: Evaluate Expert 8\n",
    "        evaluation_results = evaluate_expert8(expert8_model, X_test, y_test_pm25)\n",
    "        \n",
    "        # Step 3: Visualize results\n",
    "        plot_expert8_results(training_history, evaluation_results)\n",
    "        \n",
    "        # Step 4: Save model and metadata\n",
    "        save_expert8_metadata(expert8_model, training_history, evaluation_results, training_time)\n",
    "        \n",
    "        print(\"\\nâœ… EXPERT 8 COMPLETED SUCCESSFULLY!\")\n",
    "        print(\"ðŸ“ Model ready for ensemble stacking!\")\n",
    "        \n",
    "        # Test loading the model\n",
    "        print(\"\\nðŸ§ª Testing model loading...\")\n",
    "        loaded_model = load_expert8_model()\n",
    "        if loaded_model:\n",
    "            print(\"âœ… Model loaded successfully for ensemble integration!\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ ERROR in Expert 8: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25edab72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
