{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6687de3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, json\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f0ad780",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIFF_FOLDER = r\"C:\\Users\\NNadi\\Downloads\\Air_pollution_Agentic_AI\\GEE_AirQuality_Delhi_Daily_100m_FLOAT\"\n",
    "TIFF_GLOB = os.path.join(TIFF_FOLDER, \"AirQuality_Delhi_*.tif\")\n",
    "\n",
    "SEQ_LEN = 5\n",
    "PATCH_SIZE = 10\n",
    "PATCH_STRIDE = 64\n",
    "ALL_BANDS = 24\n",
    "PRED_BANDS = list(range(9,16))  # PM2.5…AOD → 7 dynamic pollutant bands\n",
    "\n",
    "SAVE_DIR = \"./datasets\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dd909bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: (34, 24, 402, 402)\n"
     ]
    }
   ],
   "source": [
    "def load_tifs_sorted(pattern):\n",
    "    files = sorted(glob.glob(pattern))\n",
    "    data_list = []\n",
    "\n",
    "    for f in files:\n",
    "        with rasterio.open(f) as src:\n",
    "            arr = src.read()  # shape = (24, H, W)\n",
    "            if arr.shape[0] != ALL_BANDS:\n",
    "                raise ValueError(f\"Incorrect band count in {f}: got {arr.shape[0]}\")\n",
    "            data_list.append(arr.astype(np.float32))\n",
    "\n",
    "    data = np.stack(data_list, axis=0)  # (days, 24, H, W)\n",
    "    return data, files\n",
    "\n",
    "data_all, file_list = load_tifs_sorted(TIFF_GLOB)\n",
    "print(\"Loaded:\", data_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7217a3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = np.nan_to_num(data_all, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "band_min = np.percentile(data_all, 1, axis=(0,2,3))\n",
    "band_max = np.percentile(data_all, 99, axis=(0,2,3))\n",
    "band_range = np.maximum(band_max - band_min, 1)\n",
    "\n",
    "data_norm = ((data_all - band_min[None,:,None,None]) / band_range[None,:,None,None])\n",
    "data_norm = np.clip(data_norm, 0, 1).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42c01771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence dataset: (29, 5, 402, 402, 24) (29, 402, 402, 7)\n"
     ]
    }
   ],
   "source": [
    "def make_sequences(data_norm, seq_len, pred_band_idx):\n",
    "    X_list, y_list = [], []\n",
    "    D, C, H, W = data_norm.shape\n",
    "\n",
    "    for i in range(D - seq_len):\n",
    "        seq = data_norm[i:i+seq_len]      # (5,24,H,W)\n",
    "        nxt = data_norm[i+seq_len]        # (24,H,W)\n",
    "\n",
    "        # Convert sequence → (5,H,W,24)\n",
    "        seq = np.transpose(seq, (0,2,3,1))\n",
    "\n",
    "        # Convert target → (H,W,pred_bands)\n",
    "        y = np.transpose(nxt, (1,2,0))[..., pred_band_idx]\n",
    "\n",
    "        X_list.append(seq)\n",
    "        y_list.append(y)\n",
    "\n",
    "    return np.array(X_list), np.array(y_list)\n",
    "\n",
    "X_full, y_full = make_sequences(data_norm, SEQ_LEN, PRED_BANDS)\n",
    "print(\"Sequence dataset:\", X_full.shape, y_full.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f98d184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch shapes: (1421, 5, 10, 10, 24) (1421, 10, 10, 7)\n"
     ]
    }
   ],
   "source": [
    "def extract_patches(X, y, patch, stride):\n",
    "    PX, PY = [], []\n",
    "    N, T, H, W, C = X.shape\n",
    "\n",
    "    for i in range(N):\n",
    "        for r in range(0, H - patch + 1, stride):\n",
    "            for c in range(0, W - patch + 1, stride):\n",
    "                PX.append(X[i, :, r:r+patch, c:c+patch, :])\n",
    "                PY.append(y[i,     r:r+patch, c:c+patch, :])\n",
    "\n",
    "    return np.array(PX, dtype=np.float32), np.array(PY, dtype=np.float32)\n",
    "\n",
    "X_all, y_all = extract_patches(X_full, y_full, PATCH_SIZE, PATCH_STRIDE)\n",
    "print(\"Patch shapes:\", X_all.shape, y_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14f815e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (994, 5, 10, 10, 24)\n",
      "Val  : (213, 5, 10, 10, 24)\n",
      "Test : (214, 5, 10, 10, 24)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_all, y_all, test_size=0.30, random_state=42)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=42)\n",
    "\n",
    "print(\"Train:\", X_train.shape)\n",
    "print(\"Val  :\", X_val.shape)\n",
    "print(\"Test :\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c44dbec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(SAVE_DIR, \"X_train.npy\"), X_train)\n",
    "np.save(os.path.join(SAVE_DIR, \"y_train.npy\"), y_train)\n",
    "\n",
    "np.save(os.path.join(SAVE_DIR, \"X_val.npy\"), X_val)\n",
    "np.save(os.path.join(SAVE_DIR, \"y_val.npy\"), y_val)\n",
    "\n",
    "np.save(os.path.join(SAVE_DIR, \"X_test.npy\"), X_test)\n",
    "np.save(os.path.join(SAVE_DIR, \"y_test.npy\"), y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ea375f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dataset + metadata to: ./datasets\n"
     ]
    }
   ],
   "source": [
    "meta = {\n",
    "    \"sequence_length\": SEQ_LEN,\n",
    "    \"patch_size\": PATCH_SIZE,\n",
    "    \"stride\": PATCH_STRIDE,\n",
    "    \"bands_total\": ALL_BANDS,\n",
    "    \"predict_bands\": PRED_BANDS,\n",
    "    \"dataset_shapes\": {\n",
    "        \"X_train\": list(X_train.shape),\n",
    "        \"y_train\": list(y_train.shape),\n",
    "        \"X_val\":   list(X_val.shape),\n",
    "        \"y_val\":   list(y_val.shape),\n",
    "        \"X_test\":  list(X_test.shape),\n",
    "        \"y_test\":  list(y_test.shape),\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(os.path.join(SAVE_DIR, \"metadata.json\"), \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(\"Saved dataset + metadata to:\", SAVE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3892e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
